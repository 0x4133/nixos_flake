# API Caller - Design Document

## Architecture Overview

API Caller is built as a visual workflow editor that allows users to chain API calls and data transformations. The application follows a node-based architecture where each node represents a specific operation (API call, data transformation, or output display).

## Core Components

### 1. State Management (Zustand)

**Choice**: Zustand was selected over Redux for its simplicity and minimal boilerplate.

**Architecture**:
```typescript
interface AppStore {
  currentProject: Project | null;
  theme: 'light' | 'dark';
  selectedNodeId: string | null;
  isRunning: boolean;
  executionLogs: LogEntry[];
  // Actions
  setTheme: (theme: 'light' | 'dark') => void;
  createProject: (name: string) => void;
  // ... other actions
}
```

**Benefits**:
- Automatic persistence to localStorage
- Type-safe state updates
- Minimal bundle size
- Easy testing and debugging

### 2. Graph Execution Engine

#### Topological Sorting Algorithm

The execution engine uses Kahn's algorithm for topological sorting to determine the correct execution order:

```typescript
function topologicalSort(graph: Graph): string[] {
  const inDegree: Record<string, number> = {};
  const adjacencyList: Record<string, string[]> = {};
  
  // Initialize in-degrees and adjacency list
  for (const node of graph.nodes) {
    inDegree[node.id] = 0;
    adjacencyList[node.id] = [];
  }
  
  // Build adjacency list and calculate in-degrees
  for (const edge of graph.edges) {
    adjacencyList[edge.source].push(edge.target);
    inDegree[edge.target]++;
  }
  
  // Kahn's algorithm
  const queue: string[] = [];
  const result: string[] = [];
  
  // Add nodes with no incoming edges
  for (const node of graph.nodes) {
    if (inDegree[node.id] === 0) {
      queue.push(node.id);
    }
  }
  
  while (queue.length > 0) {
    const current = queue.shift()!;
    result.push(current);
    
    for (const neighbor of adjacencyList[current]) {
      inDegree[neighbor]--;
      if (inDegree[neighbor] === 0) {
        queue.push(neighbor);
      }
    }
  }
  
  return result;
}
```

#### Cycle Detection

Uses depth-first search to detect cycles before execution:

```typescript
function detectCycles(graph: Graph): string[] {
  const visited = new Set<string>();
  const recursionStack = new Set<string>();
  const cycles: string[] = [];
  
  function dfs(nodeId: string, path: string[] = []): boolean {
    if (recursionStack.has(nodeId)) {
      const cycleStart = path.indexOf(nodeId);
      cycles.push(...path.slice(cycleStart));
      return true;
    }
    
    if (visited.has(nodeId)) {
      return false;
    }
    
    visited.add(nodeId);
    recursionStack.add(nodeId);
    
    const outgoingEdges = graph.edges.filter(edge => edge.source === nodeId);
    for (const edge of outgoingEdges) {
      if (dfs(edge.target, [...path, nodeId])) {
        return true;
      }
    }
    
    recursionStack.delete(nodeId);
    return false;
  }
  
  // Check all nodes
  for (const node of graph.nodes) {
    if (!visited.has(node.id)) {
      dfs(node.id);
    }
  }
  
  return cycles;
}
```

### 3. Variable Interpolation System

The interpolation system allows users to reference outputs from upstream nodes using `{{path.to.value}}` syntax:

```typescript
function interpolateVariables(template: string, nodeOutputs: Record<string, any>): string {
  return template.replace(/\{\{([^}]+)\}\}/g, (match, path) => {
    try {
      // Flatten all node outputs into a single object
      const allData = Object.values(nodeOutputs).reduce((acc, output, index) => {
        acc[`node${index}`] = output;
        return acc;
      }, {} as Record<string, any>);
      
      // Add first node's data as default 'data' reference
      const firstOutput = Object.values(nodeOutputs)[0];
      if (firstOutput) {
        allData.data = firstOutput;
      }
      
      const value = getNestedValue(allData, path.trim());
      return value !== undefined ? String(value) : match;
    } catch (error) {
      console.warn(`Failed to interpolate variable: ${path}`, error);
      return match;
    }
  });
}
```

### 4. Safe JavaScript Evaluation

Transform nodes use a restricted execution environment to prevent security issues:

```typescript
function safeEval(expression: string, data: any): any {
  const context: SafeEvalContext = {
    _: fp,           // lodash/fp
    data,            // input data
    Math,            // mathematical functions
    JSON,            // JSON utilities
    Array,           // array constructor
    Object,          // object utilities
    String,          // string utilities
    Number,          // number utilities
    Boolean,         // boolean utilities
    Date,            // date utilities
    RegExp,          // regex utilities
  };
  
  const safeFunction = new Function(
    ...Object.keys(context),
    `"use strict"; return (${expression});`
  );
  
  return safeFunction(...Object.values(context));
}
```

**Security Considerations**:
- No access to `window`, `document`, `global`, etc.
- No `eval`, `Function` constructor (except for the safe wrapper)
- No `setTimeout`, `setInterval`, or other async functions
- Restricted to safe built-in objects and lodash/fp

### 5. Node Execution Pipeline

Each node type has a specific execution function:

```typescript
// API Node Execution
async function executeApiNode(node, context, onLog) {
  const { method, url, headers, body, useCorsProxy } = node.data;
  
  // Interpolate variables
  const interpolatedUrl = interpolateVariables(url, context.nodeOutputs);
  const interpolatedHeaders = interpolateVariables(headers, context.nodeOutputs);
  const interpolatedBody = interpolateVariables(body, context.nodeOutputs);
  
  // Make HTTP request
  const response = await axios({
    method,
    url: useCorsProxy ? `https://cors-anywhere.herokuapp.com/${interpolatedUrl}` : interpolatedUrl,
    headers: interpolatedHeaders,
    data: interpolatedBody,
    timeout: 30000,
    validateStatus: () => true,
  });
  
  return {
    status: response.status,
    statusText: response.statusText,
    headers: response.headers,
    data: response.data,
  };
}

// Transform Node Execution
async function executeTransformNode(node, context, onLog) {
  const { expression } = node.data;
  const inputData = getNodeInputData(node.id, context);
  
  return safeEval(expression, inputData);
}

// Output Node Execution
async function executeOutputNode(node, context, onLog) {
  return getNodeInputData(node.id, context);
}
```

## Performance Considerations

### 1. Node Limit
The application is designed to handle ~50 nodes on mid-range hardware. Key optimizations:

- **Lazy Loading**: Monaco Editor only loads when Output nodes are expanded
- **Virtual Scrolling**: Large execution logs use virtual scrolling
- **Debounced Updates**: Node state updates are debounced to prevent excessive re-renders
- **Memoization**: React.memo for expensive components

### 2. Memory Management
- **Garbage Collection**: Automatic cleanup of completed node outputs
- **Streaming**: Large responses are streamed rather than buffered
- **Abort Controllers**: HTTP requests can be cancelled

### 3. Bundle Size
- **Code Splitting**: Monaco Editor and React Flow are code-split
- **Tree Shaking**: Unused lodash functions are eliminated
- **Dynamic Imports**: Heavy dependencies are loaded on-demand

## Error Handling Strategy

### 1. Graceful Degradation
- **Node Failures**: Individual node failures don't stop the entire graph
- **Partial Results**: Nodes can work with partial or missing data
- **Fallback Values**: Default values for missing interpolated variables

### 2. Error Recovery
- **Retry Logic**: Failed API calls can be retried
- **Circuit Breaker**: Prevents cascading failures
- **Timeout Handling**: Configurable timeouts for all operations

### 3. User Feedback
- **Real-time Status**: Live updates during execution
- **Detailed Logs**: Comprehensive error messages and stack traces
- **Visual Indicators**: Color-coded node status and error states

## Security Architecture

### 1. Input Validation
- **Schema Validation**: All node configurations are validated
- **Type Checking**: Runtime type checking for all inputs
- **Sanitization**: HTML and script injection prevention

### 2. Execution Safety
- **Sandboxed Evaluation**: Transform expressions run in restricted environment
- **Resource Limits**: Memory and CPU usage limits
- **Network Security**: HTTPS enforcement and CORS handling

### 3. Data Protection
- **Local Storage**: Sensitive data is not persisted
- **Encryption**: API keys and tokens are encrypted in storage
- **Access Control**: No unauthorized access to user data

## Testing Strategy

### 1. Unit Tests
- **Execution Engine**: Test topological sorting and cycle detection
- **Node Execution**: Test individual node types
- **Utilities**: Test interpolation and safe evaluation

### 2. Integration Tests
- **Graph Execution**: Test complete workflow execution
- **State Management**: Test Zustand store operations
- **API Integration**: Test with mock APIs

### 3. E2E Tests
- **User Workflows**: Test complete user journeys
- **Performance**: Test with large graphs
- **Cross-browser**: Test in multiple browsers

## Future Enhancements

### 1. Advanced Features
- **Parallel Execution**: Execute independent nodes in parallel
- **Conditional Logic**: Add conditional branching nodes
- **Loops**: Support for iterative operations
- **Subgraphs**: Reusable workflow components

### 2. Performance Improvements
- **Web Workers**: Move heavy computation to background threads
- **Caching**: Intelligent caching of API responses
- **Optimization**: Automatic graph optimization

### 3. Developer Experience
- **Debugging Tools**: Step-through execution
- **Profiling**: Performance profiling and analysis
- **Hot Reloading**: Live reload for development

## Conclusion

The API Caller architecture prioritizes simplicity, performance, and security while providing a powerful and intuitive user experience. The modular design allows for easy extension and maintenance, while the robust execution engine ensures reliable operation even with complex workflows. 